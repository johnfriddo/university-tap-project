services:

  kafka:
    image: bitnami/kafka:3.7
    ports:
      - "9094:9094"
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
    volumes:
      - kafka_data:/bitnami/kafka

  topics:
    image: bitnami/kafka:3.7
    depends_on:
      kafka:
        condition: service_started
    restart: "no"
    command: >
      bash -c "
        for i in {1..10}; do
          kafka-topics.sh --bootstrap-server kafka:9092 --list && break
          echo 'Kafka not ready yet, retrying...'
          sleep 5
        done &&
        kafka-topics.sh --create --if-not-exists --topic telegram_messages --bootstrap-server kafka:9092 &&
        kafka-topics.sh --create --if-not-exists --topic events_for_indexing --bootstrap-server kafka:9092 &&
        kafka-topics.sh --create --if-not-exists --topic telegram_notifications --bootstrap-server kafka:9092
      "

  telegram-bot:
    build:
      context: ./telegram-bot
      dockerfile: Dockerfile
    image: calendartap/telegram-bot
    restart: always
    environment:
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - KAFKA_BROKER_URL=kafka:9092
    depends_on:
      topics:
          condition: service_completed_successfully

  spark:
    build:
      context: ./spark
      dockerfile: Dockerfile
    image: calendartap/spark
    command: >
      /opt/bitnami/spark/bin/spark-submit
      --conf spark.driver.extraJavaOptions='-Divy.cache.dir=/tmp -Divy.home=/tmp'
      --master local[*]
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0
      /opt/bitnami/spark/app/app.py
    ports:
      - "4040:4040"
    env_file:
      - .env
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/opt/bitnami/spark/app/credentials/gcp_service_account.json
    depends_on:
      topics:
          condition: service_completed_successfully

  logstash:
    image: docker.elastic.co/logstash/logstash:8.14.0
    depends_on:
        - topics
        - spark
    environment:
        XPACK_MONITORING_ENABLED: "false"
    volumes:
        - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro

  elasticsearch:
    image: elasticsearch:8.14.0
    environment:
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      
  grafana:
    image: grafana/grafana-enterprise:latest
    ports:
      - '3000:3000'
    environment:
      GF_USERS_DEFAULT_LANGUAGE: it-IT
      GF_AUTH_ANONYMOUS_ENABLED: true
    depends_on:
      - elasticsearch
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  kafka_data:
  elasticsearch_data:
  grafana_data: